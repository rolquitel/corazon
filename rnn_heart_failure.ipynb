{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "test_split_size = 0.20                           # Porcentaje para test - train (20% - 80%) = 0.20\n",
    "random_state = 12                                # Valor a usar para la semilla de los algoritmos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproc_UCI():\n",
    "    datos = pd.read_csv('data/kaggle_4_datasets_12_atrib.csv')\n",
    "\n",
    "    datos['age'] = (datos['age'] - datos['age'].min()) / (datos['age'].max() - datos['age'].min())\n",
    "    datos['sex'] = datos['sex'].replace({'F':1.0, 'M':0.0})\n",
    "    datos['chest_pain_type'] = datos['chest_pain_type'].replace({'ASY':0.0, 'ATA':0.333, 'NAP': 0.667, 'TA': 1.0}) \n",
    "    datos['resting_bp'] = (datos['resting_bp'] - datos['resting_bp'].min()) / (datos['resting_bp'].max() - datos['resting_bp'].min())\n",
    "    datos['cholesterol'] = (datos['cholesterol'] - datos['cholesterol'].min()) / (datos['cholesterol'].max() - datos['cholesterol'].min())\n",
    "    datos['resting_ecg'] = datos['resting_ecg'].replace({'LVH':0.0, 'Normal':0.5, 'ST': 1.0}) \n",
    "    datos['max_hr'] = (datos['max_hr'] - datos['max_hr'].min()) / (datos['max_hr'].max() - datos['max_hr'].min())\n",
    "    datos['exercise_angina'] = datos['exercise_angina'].replace({'N':0.0, 'Y':1.0})\n",
    "    datos['oldpeak'] = (datos['oldpeak'] - datos['oldpeak'].min()) / (datos['oldpeak'].max() - datos['oldpeak'].min())\n",
    "    datos['st_slope'] = datos['st_slope'].replace({'Down':0.0, 'Flat':0.5, 'Up': 1.0})\n",
    "\n",
    "    outputs = np.array(datos['heart_disease'])\n",
    "    inputs = np.array(datos.drop(['heart_disease'], axis=1))\n",
    "\n",
    "    return train_test_split(inputs, outputs, test_size=test_split_size, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproc_SouthAfrica():\n",
    "    datos = pd.read_csv('data/south_africa_heart_disease.csv')\n",
    "\n",
    "    datos['sbp'] = (datos['sbp'] - datos['sbp'].min()) / (datos['sbp'].max() - datos['sbp'].min())\n",
    "    datos['tobacco'] = (datos['tobacco'] - datos['tobacco'].min()) / (datos['tobacco'].max() - datos['tobacco'].min())\n",
    "    datos['ldl'] = (datos['ldl'] - datos['ldl'].min()) / (datos['ldl'].max() - datos['ldl'].min())\n",
    "    datos['adiposity'] = (datos['adiposity'] - datos['adiposity'].min()) / (datos['adiposity'].max() - datos['adiposity'].min())\n",
    "    datos['famhist'] = datos['famhist'].replace({'Present':1.0, 'Absent':0.0})\n",
    "    datos['typea'] = (datos['typea'] - datos['typea'].min()) / (datos['typea'].max() - datos['typea'].min())\n",
    "    datos['obesity'] = (datos['obesity'] - datos['obesity'].min()) / (datos['obesity'].max() - datos['obesity'].min())\n",
    "    datos['alcohol'] = (datos['alcohol'] - datos['alcohol'].min()) / (datos['alcohol'].max() - datos['alcohol'].min())\n",
    "    datos['age'] = (datos['age'] - datos['age'].min()) / (datos['age'].max() - datos['age'].min())\n",
    "\n",
    "    outputs = np.array(datos['chd'])\n",
    "    inputs = np.array(datos.drop(['chd'], axis=1))\n",
    "\n",
    "    return train_test_split(inputs, outputs, test_size=test_split_size, random_state=random_state)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproc_Faisalabad():\n",
    "    datos = pd.read_csv('data/faisalabad_heart_failure_clinical_records_dataset.csv')\n",
    "\n",
    "    datos['age'] = (datos['age'] - datos['age'].min()) / (datos['age'].max() - datos['age'].min())\n",
    "    datos['creatinine_phosphokinase'] = (datos['creatinine_phosphokinase'] - datos['creatinine_phosphokinase'].min()) / (datos['creatinine_phosphokinase'].max() - datos['creatinine_phosphokinase'].min())\n",
    "    datos['ejection_fraction'] = (datos['ejection_fraction'] - datos['ejection_fraction'].min()) / (datos['ejection_fraction'].max() - datos['ejection_fraction'].min())\n",
    "    datos['platelets'] = (datos['platelets'] - datos['platelets'].min()) / (datos['platelets'].max() - datos['platelets'].min())\n",
    "    datos['serum_creatinine'] = (datos['serum_creatinine'] - datos['serum_creatinine'].min()) / (datos['serum_creatinine'].max() - datos['serum_creatinine'].min())\n",
    "    datos['serum_sodium'] = (datos['serum_sodium'] - datos['serum_sodium'].min()) / (datos['serum_sodium'].max() - datos['serum_sodium'].min())\n",
    "    datos['time'] = (datos['time'] - datos['time'].min()) / (datos['time'].max() - datos['time'].min())\n",
    "\n",
    "    outputs = np.array(datos['DEATH_EVENT'])\n",
    "    inputs = np.array(datos.drop(['DEATH_EVENT'], axis=1))\n",
    "    \n",
    "    return train_test_split(inputs, outputs, test_size=test_split_size, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproc_Framingham():\n",
    "    datos = pd.read_csv('data/framingham_chd_preprocessed_data.csv')\n",
    "\n",
    "    datos['age'] = (datos['age'] - datos['age'].min()) / (datos['age'].max() - datos['age'].min())\n",
    "    datos['cigsPerDay'] = (datos['cigsPerDay'] - datos['cigsPerDay'].min()) / (datos['cigsPerDay'].max() - datos['cigsPerDay'].min())\n",
    "    datos['totChol'] = (datos['totChol'] - datos['totChol'].min()) / (datos['totChol'].max() - datos['totChol'].min())\n",
    "    datos['sysBP'] = (datos['sysBP'] - datos['sysBP'].min()) / (datos['sysBP'].max() - datos['sysBP'].min())\n",
    "    datos['diaBP'] = (datos['diaBP'] - datos['diaBP'].min()) / (datos['diaBP'].max() - datos['diaBP'].min())\n",
    "    datos['BMI'] = (datos['BMI'] - datos['BMI'].min()) / (datos['BMI'].max() - datos['BMI'].min())\n",
    "    datos['heartRate'] = (datos['heartRate'] - datos['heartRate'].min()) / (datos['heartRate'].max() - datos['heartRate'].min())\n",
    "    datos['glucose'] = (datos['glucose'] - datos['glucose'].min()) / (datos['glucose'].max() - datos['glucose'].min())\n",
    "\n",
    "    outputs = np.array(datos['TenYearCHD'])\n",
    "    inputs = np.array(datos.drop(['TenYearCHD'], axis=1))\n",
    "    \n",
    "    return train_test_split(inputs, outputs, test_size=test_split_size, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproc(source_dataset):\n",
    "    if source_dataset == 1:\n",
    "        return preproc_UCI()\n",
    "    elif source_dataset == 2:\n",
    "        return preproc_SouthAfrica()\n",
    "    elif source_dataset == 3:\n",
    "        return preproc_Faisalabad()\n",
    "    elif source_dataset == 4:\n",
    "        return preproc_Framingham()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn as sk\n",
    "import sklearn.neural_network as sknn\n",
    "\n",
    "def run_nn(inputs_train, inputs_test, outputs_train, outputs_test, h_layers, verbose=False):\n",
    "    # Create the model\n",
    "    model = sknn.MLPClassifier(hidden_layer_sizes=h_layers, max_iter=1000, alpha=0.0001, solver='lbfgs', verbose=verbose, tol=0.000000001, random_state=1)\n",
    "    # model = sknn.MLPRegressor(solver='sgd', batch_size='auto', tol=0.0005, learning_rate_init=0.002, hidden_layer_sizes=h_layers, verbose=verbose)\n",
    "    # Train the model\n",
    "    model.fit(inputs_train, outputs_train)\n",
    "    # Predict the test set\n",
    "    \n",
    "    acc = 0\n",
    "    for i in range(0, len(inputs_test)):\n",
    "        pre = round(model.predict(inputs_test[i].reshape(1, -1))[0], 0)\n",
    "        acc = acc + 1 if pre == outputs_test[i] else acc\n",
    "        success = \"#\" if pre == outputs_test[i] else \".\"\n",
    "        if verbose:\n",
    "            print(success, end=\"\")\n",
    "\n",
    "    acc = acc / len(inputs_test)\n",
    "    # print(\"\\nAccuracy:\", acc)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "\n",
    "def run_dataset(dataset, min_nhl=1, max_nhl=4, neurons=[6, 8, 10, 12]):\n",
    "    inputs_train, inputs_test, outputs_train, outputs_test = preproc(dataset)\n",
    "\n",
    "    res = {}\n",
    "    max = 0\n",
    "    max_lyr_conf = ()\n",
    "\n",
    "    n_models = 0\n",
    "    for nhl in range(min_nhl, max_nhl+1):\n",
    "        n_models = n_models + len(neurons)**nhl\n",
    "\n",
    "    # print(\"Number of models:\", n_models)\n",
    "    cur_model = 0\n",
    "\n",
    "    for nhl in range(min_nhl, max_nhl+1):\n",
    "        for lyrs_cfg in itertools.product(neurons, repeat=nhl):\n",
    "            acc = run_nn(inputs_train, inputs_test, outputs_train, outputs_test, lyrs_cfg, verbose=False)\n",
    "            if acc > max:\n",
    "                max_lyr_conf = lyrs_cfg\n",
    "                max = acc\n",
    "                # print(\"\\nNew max:\", max, \"with\", max_lyr_conf)\n",
    "\n",
    "            res[lyrs_cfg] = acc\n",
    "            pp = str(round(cur_model / n_models * 100, 2)) + '%\\r'\n",
    "            print('Processing dataset', dataset, pp, end=\"\")\n",
    "            cur_model = cur_model + 1\n",
    "\n",
    "    print('Max acc:', max, 'Max config:', max_lyr_conf, 'for dataset', dataset)\n",
    "\n",
    "    # return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "import random\n",
    "\n",
    "class Datos:\n",
    "    def __init__(self, n_datos=250, n_muestras=100) -> None:\n",
    "        self.categorias = []\n",
    "        self.datos = {}\n",
    "        self.n_datos = n_datos\n",
    "        self.n_muestras = n_muestras\n",
    "\n",
    "        self.TAM_CODIFICACION = 7\n",
    "        self.ESPACIO_CODIFICACION = 2 ** self.TAM_CODIFICACION\n",
    "\n",
    "    def generar_uno(self, factor):\n",
    "        pass\n",
    "\n",
    "    def generar(self):\n",
    "        for nivel in range(6):\n",
    "            factor = (0.5 + nivel) / 8\n",
    "            cat = 'park_' + str(nivel)\n",
    "            self.categorias.append(cat)\n",
    "            self.datos[cat] = []\n",
    "            for i in range(self.n_datos):\n",
    "                self.datos[cat].append(self.generar_uno(factor))\n",
    "\n",
    "    def dato_de_categoria(self, cat):\n",
    "        return self.datos[cat][random.randint(0, len(self.datos[cat]) - 1)]\n",
    "\n",
    "    def dato_al_azar(self):    \n",
    "        def random_choice(a):\n",
    "            random_idx = random.randint(0, len(a) - 1)\n",
    "            return a[random_idx]\n",
    "        \n",
    "        categoria = random_choice(self.categorias)\n",
    "        dato = random_choice(self.datos[categoria])\n",
    "        categoria_tensor = torch.tensor([self.categorias.index(categoria)], dtype=torch.long)\n",
    "        dato_tensor = self.datos_a_tensor(dato)\n",
    "        return categoria, dato, categoria_tensor, dato_tensor\n",
    "\n",
    "    def datos_a_short(self, datos):\n",
    "        min = np.min(datos)\n",
    "        max = np.max(datos)\n",
    "\n",
    "        MAX_VAL = 2 ** self.TAM_CODIFICACION - 1\n",
    "\n",
    "        return np.round(MAX_VAL * (datos - min) / (max - min))\n",
    "\n",
    "    def datos_a_bin(self, datos):\n",
    "        def numAbin(n):\n",
    "            n = int(n)\n",
    "            b = []\n",
    "            for i in range(self.TAM_CODIFICACION):\n",
    "                b.append(n % 2)\n",
    "                n = int(n / 2)\n",
    "            return b\n",
    "\n",
    "        res = []\n",
    "        for v in datos:\n",
    "            res.append(numAbin(v))\n",
    "\n",
    "        return res\n",
    "\n",
    "    \"\"\"\n",
    "    Codificar una secuencia de marcha en un tensor, mediante convertir cada dato en \n",
    "    un espacio de 2 ** N_BITS bits\n",
    "    \"\"\"\n",
    "    def datos_a_tensor(self, datos):\n",
    "        datos = self.datos_a_short(datos)\n",
    "\n",
    "        tensor = torch.zeros(len(datos), 1, self.ESPACIO_CODIFICACION)     # long de la marcha * 1 * 8 bits\n",
    "        for d in range(len(datos)):\n",
    "            tensor[d][0][int(datos[d])] = 1\n",
    "\n",
    "        return tensor\n",
    "\n",
    "    \"\"\"\n",
    "    Determinar la categoría de salida\n",
    "    \"\"\"\n",
    "    def que_catogoria(self, output):\n",
    "        category_idx = torch.argmax(output).item()\n",
    "        return self.categorias[category_idx]\n",
    "\n",
    "\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    # implement RNN from scratch rather than using nn.RNN\n",
    "    #def __init__(self, input_size, hidden_size, output_size):\n",
    "    def __init__(self, dataset, hidden_size=128):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        input_size = dataset.ESPACIO_CODIFICACION\n",
    "        output_size = len(dataset.categorias)\n",
    "\n",
    "        self.dataset = dataset\n",
    "        self.hidden_size = hidden_size\n",
    "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.i2o = nn.Linear(input_size + hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "    def forward(self, input_tensor, hidden_tensor):\n",
    "        combined = torch.cat((input_tensor, hidden_tensor), 1)\n",
    "        \n",
    "        hidden = self.i2h(combined)\n",
    "        output = self.i2o(combined)\n",
    "        output = self.softmax(output)\n",
    "\n",
    "        return output, hidden\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)\n",
    "\n",
    "    def train_step(self, data_tensor, category_tensor, criterion, optimizer):\n",
    "        hidden = self.init_hidden()\n",
    "        \n",
    "        for i in range(data_tensor.size()[0]):\n",
    "            output, hidden = self(data_tensor[i], hidden)\n",
    "            \n",
    "        loss = criterion(output, category_tensor)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        return output, loss.item()\n",
    "\n",
    "    def train(self,\n",
    "              lr=0.005,\n",
    "              n_iters=100000, \n",
    "              plot_steps=1000, \n",
    "              print_steps=5000):\n",
    "        \n",
    "        criterion = nn.NLLLoss()\n",
    "        optimizer = torch.optim.SGD(self.parameters(), lr=lr)\n",
    "        current_loss = 0\n",
    "        self.all_losses = []\n",
    "\n",
    "        ok = 0\n",
    "        nok = 0\n",
    "\n",
    "        for i in range(n_iters):\n",
    "            category, data, category_tensor, data_tensor = self.dataset.dato_al_azar()\n",
    "            \n",
    "            output, loss = self.train_step(data_tensor, category_tensor, criterion, optimizer)\n",
    "            current_loss += loss \n",
    "            \n",
    "            if (i+1) % plot_steps == 0:\n",
    "                self.all_losses.append(current_loss / plot_steps)\n",
    "                current_loss = 0\n",
    "                \n",
    "            if (i+1) % print_steps == 0:\n",
    "                guess = self.dataset.que_catogoria(output)\n",
    "                correct = \"OK\" if guess == category else f\"NO ({category})\"\n",
    "                pdata = len(data)\n",
    "                print(f\"{i+1} {((i+1)/n_iters*100):.1f}% {loss:.4f} {pdata} / {guess} {correct}\")\n",
    "                if loss < 1:\n",
    "                    break\n",
    "\n",
    "\n",
    "    def predict(self, input):\n",
    "        #print(f\"\\n> {input_line}\")\n",
    "        with torch.no_grad():\n",
    "            input_tensor = self.dataset.datos_a_tensor(input)\n",
    "            \n",
    "            hidden = self.init_hidden()\n",
    "        \n",
    "            for i in range(input_tensor.size()[0]):\n",
    "                output, hidden = self(input_tensor[i], hidden)\n",
    "            \n",
    "            guess = self.dataset.que_catogoria(output)\n",
    "            print(guess)\n",
    "            return guess\n",
    "\n",
    "    def prueba(self):\n",
    "        with torch.no_grad():\n",
    "            category, data, category_tensor, data_tensor = self.dataset.dato_al_azar()\n",
    "\n",
    "            hidden = self.init_hidden()\n",
    "\n",
    "            for i in range(data_tensor.size()[0]):\n",
    "                output, hidden = self(data_tensor[i], hidden)\n",
    "            \n",
    "            guess = self.dataset.que_catogoria(output)\n",
    "\n",
    "            return guess == category\n",
    "\n",
    "    def test(self, dato, cat):\n",
    "        with torch.no_grad():\n",
    "            data_tensor = self.dataset.datos_a_tensor(dato)\n",
    "\n",
    "            hidden = self.init_hidden()\n",
    "\n",
    "            for i in range(data_tensor.size()[0]):\n",
    "                output, hidden = self(data_tensor[i], hidden)\n",
    "            \n",
    "            guess = self.dataset.que_catogoria(output)\n",
    "\n",
    "            return guess\n",
    "\n",
    "    def presicion(self, n_pruebas):\n",
    "        exitos = 0\n",
    "        for i in range(n_pruebas):\n",
    "            if self.prueba():\n",
    "                exitos += 1\n",
    "                print('.', end='')\n",
    "            else:\n",
    "                print('X', end='')\n",
    "\n",
    "        print('')\n",
    "\n",
    "        return exitos / n_pruebas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import matplotlib.pyplot as plt\\nfrom sklearn.model_selection import train_test_split'); }\n    ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max acc: 0.907608695652174 Max config: (8, 6, 10) for dataset 1\n"
     ]
    }
   ],
   "source": [
    "random_state = 42\n",
    "run_dataset(1, min_nhl=2, max_nhl=4, neurons=[6, 8, 10, 12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('from sklearn.model_selection import train_test_split'); }\n    ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max acc: 0.8279569892473119 Max config: (10, 6, 10) for dataset 2\n"
     ]
    }
   ],
   "source": [
    "random_state = 24\n",
    "run_dataset(2, min_nhl=2, max_nhl=4, neurons=[6, 8, 10, 12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('from sklearn.model_selection import train_test_split'); }\n    ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max acc: 0.9 Max config: (6, 8, 10) for dataset 3\n"
     ]
    }
   ],
   "source": [
    "random_state = 40\n",
    "run_dataset(3, min_nhl=2, max_nhl=4, neurons=[6, 8, 10, 12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import matplotlib.pyplot as plt\\nfrom sklearn.model_selection import train_test_split'); }\n    ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max acc: 0.871825876662636 Max config: (6, 10, 8, 8) for dataset 4\n"
     ]
    }
   ],
   "source": [
    "random_state = 40\n",
    "run_dataset(4, min_nhl=2, max_nhl=4, neurons=[6, 8, 10, 12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random state: 37\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import matplotlib.pyplot as plt\\nfrom sklearn.model_selection import train_test_split'); }\n    ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max acc: 0.8548972188633616 Max config: (12, 8, 10, 8) for dataset 4\n",
      "Random state: 39\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import matplotlib.pyplot as plt\\nfrom sklearn.model_selection import train_test_split'); }\n    ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max acc: 0.8621523579201935 Max config: (6, 12, 12, 12) for dataset 4\n",
      "Random state: 41\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import matplotlib.pyplot as plt\\nfrom sklearn.model_selection import train_test_split'); }\n    ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max acc: 0.8440145102781137 Max config: (6, 6, 6, 6) for dataset 4\n",
      "Random state: 43\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import matplotlib.pyplot as plt\\nfrom sklearn.model_selection import train_test_split'); }\n    ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max acc: 0.8548972188633616 Max config: (6, 12, 6, 10) for dataset 4\n"
     ]
    }
   ],
   "source": [
    "# esto lu usoo para determinar el mejor valor de random_state\n",
    "for rs in range(37, 44, 2):\n",
    "    random_state = rs\n",
    "    print(\"Random state:\", random_state)\n",
    "    run_dataset(4, min_nhl=3, max_nhl=4, neurons=[6, 8, 10, 12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('healt')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a643a7513210d12ee6aa8e2f0b2211f1297b6cd298aa43627461c66130b469a6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
